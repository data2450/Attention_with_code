# Attention_with_code
understand working of attention  mechanism in Transformer arc
